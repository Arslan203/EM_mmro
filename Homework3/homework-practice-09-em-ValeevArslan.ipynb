{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение, ВМК МГУ\n",
    "\n",
    "# Практическое задание 3. EM-алгоритм\n",
    "\n",
    "## Общая информация\n",
    "Дата выдачи: 04.04.2024\n",
    "\n",
    "Мягкий дедлайн: 19.04.2024 1:30 MSK\n",
    "\n",
    "Жёсткий дедлайн: 26.04.2024 1:30 MSK\n",
    "\n",
    "## Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). **Максимальная оценка за работу  — 10 баллов + 9 бонусов.**\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "## Формат сдачи !!ВАЖНО!!!\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-09-em-Username.ipynb\n",
    "* Модули preprocessing.py, metrics.py, models.py, содержащие написанный вами код\n",
    "* **Ссылки на посылки** в Яндекс.Контест для всех функций и классов, которые вы реализовали\n",
    "\n",
    "Ссылка на Яндекс.Контест: https://contest.yandex.ru/contest/60281/\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:#de3815;font-size:25px;\">\n",
    "Напоминание об оформлении и выполнении ноутбука\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть, не запуская ячейки (кроме редких случаев, когда необходимо намеренно скрыть ненужный output, про такие случаи желательно писать пояснения в тексте). **В противном случае -1 балл**\n",
    "* При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст, если явно не указана такая возможность. **В противном случае -1 балл**\n",
    "* В anytask обязательно нужно прикреплять отдельно файл с расширением ipynb (не в архиве, а именно отдельно). Если необходимо отправить еще какие-то файлы, то вынесите их в отдельный архив (если файлов много) и пришлите. **В противном случае -0.5 балла**\n",
    "---\n",
    "* Пишите, пожалуйста, выводы и ответы на вопросы в текстовых ячейках/при помощи print в коде. При их отсутствии мы не можем понять, сделали ли вы задание и понимаете, что происходит, и **поэтому будем снижать баллы**\n",
    "* Если алгоритм не сказано реализовывать явно, его всегда можно импортировать из библиотеки.\n",
    "---\n",
    "* Про графики. _Штрафы будут применяться к каждому результату команды отображения графика (plt.show() и др. аналогичные). Исключением являются графики, генерируемые функциями каких-либо сторонних библиотек, если их нельзя кастомизировать_\n",
    "\n",
    "    * должно быть название (plt.title) графика; **В противном случае &ndash; -0.05 балла**\n",
    "    * на графиках должны быть подписаны оси (plt.xlabel, plt.ylabel); **В противном случае &ndash; -0.025 балла за каждую ось**\n",
    "    * должны быть подписаны единицы измерения (если это возможно); **В противном случае &ndash; -0.025 балла за каждую ось**\n",
    "    * все названия должны быть понятны любому человеку, знакомому с терминологией, без заглядывания в код; **В противном случае &ndash; -0.05 балла**\n",
    "    * подписи тиков на осях не должны сливаться как на одной оси, так и между ними; **В противном случае &ndash; -0.025 балла за каждую ось**\n",
    "    * если изображено несколько сущностей на одном холсте (например несколько функций), то необходима поясняющая легенда (plt.legend); **В противном случае &ndash; -0.05 балла**\n",
    "    * все линии на графиках должны быть чётко видны (нет похожих цветов или цветов, сливающихся с фоном); **В противном случае &ndash; -0.05 балла**\n",
    "    * если отображена величина, имеющая очевидный диапазон значений (например, проценты могут быть от 0 до 100), то желательно масштабировать ось на весь диапазон значений (исключением является случай, когда вам необходимо показать малое отличие, которое незаметно в таких масштабах);\n",
    "    * графики должны быть не супер-микро и не супер-макро по размерам, так, чтобы можно было увидеть все, что нужно.\n",
    "    * при необходимости улучшения наглядности графиков, можно пользоваться логарифмической шкалой по осям x/y.\n",
    "    \n",
    "    \n",
    "### А также..\n",
    "\n",
    "* Для удобства поиска вопросов, на которые от вас просят ответа, мы пометили их знаком **(?)**\n",
    "* Знак **(!)** означает, что выполнение замечания необходимо для **возможности получения полного балла**\n",
    "* Даем до +0.3 балла за выдающиеся успехи по субъективному мнению проверяющих. Этот **бонус** не апеллируется"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative model of Labels, Abilities, and Difficulties (GLAD)\n",
    "\n",
    "В [семинаре 15](https://github.com/esokolov/ml-course-hse/blob/master/2020-spring/seminars/sem15-em.pdf) мы рассмотрели задачу восстановления истинной разметки по меткам от экспертов (которым мы не можем доверять в полной мере, более того, их предсказания могут расходиться).\n",
    "\n",
    "Рассмотрим следующую вероятностную модель:\n",
    "\n",
    "$$ p(L, Z | \\alpha, \\beta) = \\prod_{i=1}^{n} \\prod_{j=1}^m \\sigma(\\alpha_j\\beta_i)^{[l_{ij}=z_i]}\\sigma(-\\alpha_j\\beta_i)^{1-[l_{ij}=z_i]} p(z_j)$$\n",
    "\n",
    "где $l_{ij} -$ ответ $j$-го эксперта на задачу $i$, $z_j -$ истинная разметка, $\\alpha_j, \\beta_i-$ уровень экспертизы и сложность задачи соответственно. Для более подробного описания модели можно прочитать материалы семинара, а также [оригинальную статью](http://papers.nips.cc/paper/3644-whose-vote-should-count-more-optimal-integration-of-labels-from-labelers-of-unknown-expertise.pdf). Априорное распределение положим равномерным: $p(z_i) = 0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seed = 0xDEADF00D\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число задач (n_problems): 2000, число экспертов (n_experts): 20\n"
     ]
    }
   ],
   "source": [
    "L = np.load('L.npy')\n",
    "n, m = L.shape\n",
    "print(f\"Число задач (n_problems): {n}, число экспертов (n_experts): {m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1. (2 балла)** Реализуйте EM-алгоритм для заданной выше модели. Вы можете воспользоваться предложенными шаблонами или написать свои. \n",
    "\n",
    "Обратите внимание, что правдоподобие моделирует не вероятность метки $l_{ij}$ принять значение 1 или 0, а вероятность того, что она равна скрытой переменной $z_i$, т.е. $p(l_{ij} = z_j|z_j, \\alpha_j, \\beta_i) \\neq p(l_{ij} = 1|\\alpha_j, \\beta_i) $. При этом заранее неизвестно, какая из скрытых переменных соответствует метке 1. Не забывайте, что параметры $\\beta_i$ должны быть неотрицательными; для этого оптимизируйте $\\log \\beta$. На M-шаге можете использовать как один шаг градиентного спуска, так и несколько: разумные результаты у вас должны получаться вне зависимости от числа итераций.\n",
    "\n",
    "**Подсказки (могут быть актуальны на все задание):**\n",
    "\n",
    "* При работе с вероятностями не забывайте о точности:\n",
    " 1. Используйте логарифмы вероятностей.\n",
    " 2. $\\log \\sigma(a)$ лучше преобразовать в $\\log \\sigma(a) = -\\log(1 + \\exp(-a)) = -\\mathrm{softplus}(-a) $\n",
    " 3. Ещё полезные функции: `scipy.special.expit`, `scipy.special.logsumexp`, `np.log1p`\n",
    "* Для отладки может быть полезно проверить градиенты, возвращаемые функциями `alpha_grad_lb` и `logbeta_grad_lb` с помощью `scipy.optimize.check_grad`.\n",
    "* Размеры возвращаемых значений, указанные в докстринге функций могут помочь вам понять, что необходимо возвращать\n",
    "* Почитайте докстринги, в них есть подсказки и ссылки на формулы из семинара\n",
    "* Если у вас вылезают где-то nan/inf -- попробуйте урезать значения снизу. Например, у вас есть место, где берется log(theta) -- тут имеет смысл урезать theta = max(theta, eps), где eps какое-то маленькое число (например 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit, softmax\n",
    "def softplus(x):\n",
    "    '''stable version of log(1 + exp(x))'''\n",
    "    c = (x > 20) * 1.\n",
    "    return np.log1p(np.exp(x * (1-c)) * (1-c)) + x * c\n",
    "\n",
    "def log_sigma(x):\n",
    "    return -softplus(-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior(alpha, beta, L):\n",
    "    \"\"\" Posterior over true labels z p(z|l, \\alpha, \\beta)\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "    Returns:\n",
    "        ndarray of shape (2, n_problems)\n",
    "        (2 -- for z = 0 and for z = 1, n_problems -- for each problem in data)\n",
    "    Tip:\n",
    "        You may use function log_likelihood here\n",
    "        See page 7 of seminar, the last formula for details\n",
    "    \"\"\"\n",
    "    res = np.stack([log_likelihood(alpha, beta, L, np.ones_like(beta) * i) for i in range(2)], axis=0)\n",
    "    return softmax(res, axis=0)\n",
    "\n",
    "\n",
    "def log_likelihood(alpha, beta, L, z, eps=1e-7):\n",
    "    \"\"\" p(l=z|z, \\alpha, \\beta)\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "        z: ndarray of shape (n_problems).\n",
    "    Returns:\n",
    "        ndarray of shape (n_problems,)\n",
    "    Tips:\n",
    "        See page 7 of seminar, the second formula for details\n",
    "    \"\"\"\n",
    "    mesh = beta[:, np.newaxis] @ alpha[np.newaxis, :]\n",
    "    mask = (L == z[:, np.newaxis])\n",
    "    apost = log_sigma(mesh) * (mask * 1.0) + log_sigma(-mesh) * (~mask * 1.0)\n",
    "    res = np.maximum(z, eps) + np.sum(apost, axis=1)\n",
    "    return res\n",
    "\n",
    "\n",
    "def alpha_grad_lb(alpha, beta, L, q):\n",
    "    \"\"\" Gradient of lower bound wrt alpha\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "        q: ndarray of shape (2, n_problems).\n",
    "    Returns:\n",
    "        ndarray of shape (n_experts,)\n",
    "    Tips:\n",
    "        See pages 8-9 of seminar for details\n",
    "    \"\"\"\n",
    "    mesh = beta[:, np.newaxis] @ alpha[np.newaxis, :]\n",
    "    mask = L == 1\n",
    "    apost = expit(-mesh) * (mask * 1.0) - expit(mesh) * (~mask * 1.0)\n",
    "    apost *= q[1][:, np.newaxis] # ???\n",
    "    \n",
    "    mask = L == 0\n",
    "    apost_1 = expit(-mesh) * (mask * 1.0) - expit(mesh) * (~mask * 1.0)\n",
    "    apost_1 *= q[0][:, np.newaxis]\n",
    "\n",
    "    res = np.sum((apost + apost_1) * beta[:, np.newaxis], axis=0)\n",
    "    return res\n",
    "\n",
    "\n",
    "def logbeta_grad_lb(alpha, beta, L, q):\n",
    "    \"\"\" Gradient of lower bound wrt beta\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "        q: ndarray of shape (2, n_problems).\n",
    "    Returns:\n",
    "        ndarray of shape (n_problems,)\n",
    "    Tips:\n",
    "        See pages 8-9 of seminar for details\n",
    "    \"\"\"\n",
    "    mesh = beta[:, np.newaxis] @ alpha[np.newaxis, :]\n",
    "    mask = L == 1\n",
    "    apost = expit(-mesh) * (mask * 1.0) - expit(mesh) * (~mask * 1.0)\n",
    "    apost *= q[1][:, np.newaxis]\n",
    "    \n",
    "    mask = L == 0\n",
    "    apost_1 = expit(-mesh) * (mask * 1.0) - expit(mesh) * (~mask * 1.0)\n",
    "    apost_1 *= q[0][:, np.newaxis]\n",
    "\n",
    "    res = np.sum((apost + apost_1) * alpha[np.newaxis, :], axis=1)\n",
    "    return res * beta # in func assume that beta = exp(beta) so grad(beta) = grad(beta) * exp(beta)\n",
    "\n",
    "\n",
    "def lower_bound(alpha, beta, L, q):\n",
    "    \"\"\" Lower bound\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "        q: ndarray of shape (2, n_problems).\n",
    "    Returns:\n",
    "        single value, number\n",
    "    Tips:\n",
    "        You may use function log_likelihood here\n",
    "        See page 8 of seminar, the fourth formula for details\n",
    "    \"\"\"\n",
    "    mesh = beta[:, np.newaxis] @ alpha[np.newaxis, :]\n",
    "    mask = L == 1\n",
    "    apost = log_sigma(mesh) * (mask * 1.0) + log_sigma(-mesh) * (~mask * 1.0)\n",
    "    apost *= q[1][:, np.newaxis]\n",
    "    \n",
    "    mask = L == 0\n",
    "    apost_1 = log_sigma(mesh) * (mask * 1.0) + log_sigma(-mesh) * (~mask * 1.0)\n",
    "    apost_1 *= q[0][:, np.newaxis]\n",
    "\n",
    "    res = np.sum(apost + apost_1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подсказка:**\n",
    "* При проверке alpha значения, выдываемые функцией `check_grad` должны быть не более 0.01. Иначе у вас где-то ошибка\n",
    "* При проверке logbeta значения, выдываемые функцией `check_grad` должны быть не более 0.05. Иначе у вас где-то ошибка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011961236591628921"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import check_grad\n",
    "\n",
    "alpha, logbeta = np.random.randn(m), np.random.randn(n)\n",
    "beta = np.exp(logbeta)\n",
    "q = np.ones((2, len(beta))) * 0.5\n",
    "\n",
    "check_grad(\n",
    "    lambda a: lower_bound(a, beta, L, q),\n",
    "    lambda a: alpha_grad_lb(a, beta, L, q),\n",
    "    alpha\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010806292188726497"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_grad(\n",
    "    lambda lb: lower_bound(alpha, np.exp(lb), L, q),\n",
    "    lambda lb: logbeta_grad_lb(alpha, np.exp(lb), L, q),\n",
    "    logbeta\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def em(L, n_steps=1000, lr=1e-3, grad_steps=10):\n",
    "    # initialize parameters\n",
    "    alpha, logbeta = np.random.randn(m), np.random.randn(n)\n",
    "    q = np.ones((2, len(beta))) * 0.5\n",
    "    # eps = 1e-7\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        q = posterior(alpha, np.exp(logbeta), L)\n",
    "        for gr_step in range(grad_steps):\n",
    "            alpha_gr = alpha_grad_lb(alpha, np.exp(logbeta), L, q)\n",
    "            logbeta_gr = logbeta_grad_lb(alpha, np.exp(logbeta), L, q)\n",
    "            alpha += lr * alpha_gr\n",
    "            logbeta += lr * logbeta_gr\n",
    "\n",
    "    return alpha, np.exp(logbeta), q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, beta, q = em(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2. (1 балл)** Загрузите настоящую разметку. Посчитайте `accuracy` разметки, полученной с помощью обычного голосования по большинству среди экспертов, и сравните его с качеством **(?)**, полученным с помощью EM-алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разбалловка:**\n",
    "* **0.5 балла** -- качество голосования не менее 0.904\n",
    "* **0.5 балла** -- качестве EM не менее 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подсказка:**\n",
    "* Помните, что алгоритму не важно, какая метка 0, а какая 1, поэтому если получите качество <0.5, то просто поменяйте метки классов (не забудьте также поменять знак у $\\alpha$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy by GOLOSOVANIE:0.904, by em:0.0495\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    return np.mean(y_pred == y_true)\n",
    "\n",
    "y = np.load('y.npy')\n",
    "# (∩ ￣ー￣)⊃ ✳✨✳✨✳✨✳\n",
    "y_pred = np.mean(L, axis=1)\n",
    "GOLOSOVANIE = accuracy((y_pred > 0.5) * 1.0, y)\n",
    "\n",
    "alpha, beta, q = em(L, grad_steps=1)\n",
    "\n",
    "y_pred_em = np.argmax(q, axis=0)\n",
    "\n",
    "print(f'accuracy by GOLOSOVANIE:{GOLOSOVANIE}, by em:{accuracy(y_pred_em, y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reversing...\n",
      "accuracy by em:0.9505\n"
     ]
    }
   ],
   "source": [
    "if accuracy(y_pred_em, y) < 0.05:\n",
    "    print('reversing...')\n",
    "    alpha = -alpha\n",
    "    q = q[[1, 0]]\n",
    "    y_pred_em = np.argmax(q, axis=0)\n",
    "    print(f'accuracy by em:{accuracy(y_pred_em, y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3. (0.5 балла)** **(?)** Попробуйте проинтерпретировать полученные коэфициенты $\\alpha$. **(?)**  Есть ли в выборке эксперты, которые намеренно голосуют неверно? **(?)**  Как это можно понять по альфам? \n",
    "\n",
    "* Продемонстрируйте, что эксперты действительно чаще голосуют за неверный класс. \n",
    "* Отобразите визуализацию зависимости доли врено размеченных экспертом объектов от коэффициента $\\alpha$.\n",
    "* **(?)**  Прокомментируйте результаты и полученную зависимость."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подсказки:**\n",
    "* Если вы отобразили или хотели отобразить зависимость при помощи обычного plot (график), то посмотрите повнимательнее/подумайте, почему это не очень хорошая визуализация. **Для возможности получения полного балла** правильно будет использовать тип отображения scatter plot.\n",
    "*  Также **для возможности получения полного балла** вам необходимо проинтерпретировать смысл зависимости для всех групп альф, которые вы увидите (спойлер: их должно быть 3:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"darkgrid\")\n",
    "# (∩ᄑ_ᄑ)⊃━☆ﾟ*･｡*\n",
    "true_frac = np.mean(L == y[:, np.newaxis], axis=0)\n",
    "sns.scatterplot(x=alpha, y=true_frac).set(title = 'dependancy of the fraction of correct answers on alpha', xlabel='alpha', ylabel='proportion of correct answers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответы:** Зависимость $\\alpha$ от доли верных ответов линейная. В рамках поставленной вероятностной модели ясно, что при $\\alpha$ < 0 эксперт будет намеренно выдавать неверную разметку (accuracy < 0.5). В данной модели 4 эксперта имеют $\\alpha$ < 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4. (бонус, 1 балл)**  Как уже было замечено выше, модели не важно, какой класс 1, а какой 0. Скажем, если все эксперты оказались максимально противными и ставят метку с точностью наоборот, то у вас будет полная согласованность между экспертами, при этом невозможно понять правильно они разметили выборку или нет, смотря только на такую разметку. Чтобы избежать этого, можно включать в выборку вопрос с заведомо известным ответом, тогда вы сможете определить, ставит ли эксперт специально неверные метки.\n",
    "\n",
    "Чтобы обощить данную модель на случай заданий с заведомо известной меткой, достоточно не делать для них E-шаг, а всегда полагать апостериорное распределение вырожденным в истинном классе. \n",
    "\n",
    "* Реализуйте данную модель и используйте истинную разметку *для нескольких* задач из обучения. \n",
    "* **(?)**  Сравните модифицированный алгоритм с обычным. \n",
    "* **(?)** Проинтерпретируйте полученные результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подсказка:**\n",
    "* Как можно сравнить, что модифицированный алгоритм действительно \"лучше\" обычного: запускаем обычный и модифицированный много раз (например, 100). Для каждой версии считаем распределение полученных accuracy_score. Если все сделано верно, то в модифицированной версии доля больших значений accuracy должна быть выше, чем низких (это как раз и есть сигнал о перепутывании классов), а в обычной версии -- доли должны быть примерно равны. **Для возможности получения полного балла мы ожидаем от вас какого-то такого или похожего сравнения**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (∩ᄑ_ᄑ)⊃━☆ﾟ*･｡*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выравнивание слов (Word Alignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EM-алгоритм также применяют на практике для настройки параметров модели выравнивания слов, более сложные модификации которой используются в статистическом машинном переводе. Мы не будем подробно обсуждать применение word alignment для перевода и ограничимся следующей целью: пусть у нас есть параллельный корпус из предложений на исходном языке и их переводов на целевой язык (в этом задании используются английский и чешский соответственно). \n",
    "\n",
    "Первая задача — определить с помощью этого корпуса, как переводится каждое отдельное слово на целевом языке. Вторая задача — для произвольной пары из предложения и его перевода установить, переводом какого слова в исходном предложении является каждое слово в целевом предложении. Оказывается, у обеих задач существует элегантное и эффективное решение при введении правильной вероятностной модели: в этой части задания вам предстоит его реализовать и оценить результаты работы. Но обо всём по порядку :)\n",
    "\n",
    "---\n",
    "\n",
    "Перед тем, как заниматься машинным обучением, давайте разберёмся с данными и метриками в интересующей нас задаче. В ячейке ниже загружается и разархивируется параллельный английско-чешский корпус, в котором есть разметка выравнивания слов. Нетрудно заметить, что формат XML-файла, использованный его авторами, не вполне стандартный: нет готовой команды , которая позволила бы получить список пар предложений вместе с выравниваниями. Это значит, что нужно разобраться с форматом и написать парсер самостоятельно, используя встроенные средства Python, например, модуль [xml](https://docs.python.org/3.7/library/xml.html).\n",
    "\n",
    "**Подсказка:**\n",
    "* Не обязательно парсить только через xml, если хотите, можете написать парсинг сами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n",
      "<sentences>\n",
      "<s id=\"project_syndicate_bacchetta1-s1\">\n",
      "  <english>Are the Dollar 's Days Numbered ?</english>\n",
      "  <czech>Jsou dny dolaru sečteny ?</czech>\n",
      "  <sure>1-1 3-3 5-2 6-4 7-5</sure>\n",
      "  <possible>2-2 4-3</possible>\n",
      "</s>\n",
      "<s id=\"project_syndicate_bacchetta1-s2\">\n",
      "  <english>Philippe Bacchetta and Eric van Wincoop</english>\n",
      "  <czech>Philippe Bacchetta and Eric van Wincoop</czech>\n",
      "  <sure>1-1 2-2 3-3 4-4 5-5 6-6</sure>\n",
      "  <possible></possible>\n",
      "</s>\n",
      "<s id=\"project_syndicate_bacchetta1-s3\">\n",
      "  <english>A year ago , the dollar bestrode the world like a colossus .</english>\n",
      "  <czech>Ještě před rokem dolar dominoval světu jako imperátor .</czech>\n",
      "  <sure>10-7 12-8 13-9 2-3 3-2 6-4 7-5 9-6</sure>\n",
      "  <possible>1-3 11-8 3-1 5-4 8-6</possible>\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget -q https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-1804/CzEnAli_1.0.tar.gz -O CzEnAli_1.0.tar.gz\n",
    "mkdir -p data\n",
    "tar -xzf CzEnAli_1.0.tar.gz -C data/\n",
    "head -n 20 data/merged_data/project_syndicate/project_syndicate_bacchetta1.wa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание -2. (0.5 балла)** Реализуйте функцию `extract_sentences`, которая принимает на вход путь к файлу с XML-разметкой, используемой в этом датасете, и возвращает список параллельных предложений, а также список из «уверенных» (sure) и «возможных» (possible) пар выравниваний. Отправьте вашу реализацию в Яндекс.Контест, чтобы убедиться в её корректности; в следующей ячейке ноутбука соберите все пары размеченных предложений из датасета в два списка `all_sentences` (список `SentencePair`) и `all_targets` (список LabeledAlignment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подсказка:**\n",
    "* Брать файлы нужно из всей папки data конструкцией наподобие `for file in glob.glob('data/*/*/*.wa')`\n",
    "* Возможно у вас не будут проходить тесты, но вы не будете понимать, в чем же дело:) Попробуйте в таком случае заменить & на `&amp;` или \n",
    "`&#038;`\n",
    "https://stackoverflow.com/questions/17423495/how-to-solve-ampersand-conversion-issue-in-xml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Замечание:** \n",
    "* **Полностью проходящая все тесты посылка в этом заданиии дает 0.5 балла. За непроходящий хотя бы 1 тест вы получите 0 баллов.**\n",
    "* Здесь и далее соблюдайте сигнатуры функций и пользуйтесь объявленными в модуле `preprocessing.py` классами для организации данных. Стоит заметить, что предложения уже токенизированы (даже отделена пунктуация), поэтому предобработку текстов совершать не нужно. Обратите внимание на формат хранения выравниваний: нумерация начинается с 1 (в таком виде и нужно сохранять), первым в паре идёт слово из англоязычного предложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**https://contest.yandex.ru/contest/60281/run-report/112331534/**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from preprocessing import extract_sentences\n",
    "\n",
    "all_sentences = []\n",
    "all_targets = []\n",
    "# (´◕▽◕)⊃━☆\n",
    "\n",
    "for file in glob.glob('data/*/*/*.wa'):\n",
    "    sents, targ = extract_sentences(file)\n",
    "    all_sentences += sents\n",
    "    all_targets += targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import preprocessing\n",
    "\n",
    "preprocessing = reload(preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание -1. (0.5 балла)** Реализуйте функции `get_token_to_index` и `tokenize_sents` из модуля `preprocessing.py`, постройте словари token->index для обоих языков и постройте список из `TokenizedSentencePair` по выборке. Реализации функций также отправьте в Яндекс.Контест."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Замечание:** \n",
    "* **Полностью проходящая все тесты посылка в этом заданиии дает 0.5 балла. За непроходящий хотя бы 1 тест вы получите 0 баллов.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**>>Ваша ссылка на посылку:<<**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import get_token_to_index, tokenize_sents\n",
    "\n",
    "t_idx_src, t_idx_tgt = get_token_to_index(all_sentences)\n",
    "tokenized_sentences = tokenize_sents(all_sentences, t_idx_src, t_idx_tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве бейзлайна для этой задачи мы возьмём способ выравнивания слов по коэффициенту Дайса: слово в исходном языке является переводом слова на целевом языке, если они часто встречаются в одних и тех же предложениях и редко встречаются по отдельности. \n",
    "\n",
    "Математически это записывается по аналогии с мерой Жаккара: пусть $c(x,y)$ — число параллельных предложений, в которых есть и $x$ (на исходном языке), и $y$ (на целевом языке), а $c(x)$ и $c(y)$ — суммарное количество предложений, в которых встречается слово $x$ и $y$ соответственно. Тогда $\\textrm{Dice}(x,y)=\\frac{2 \\cdot c(x,y)}{c(x) + c(y)}$ — характеристика «похожести» слов $x$ и $y$. Она равна 1, если слова встречаются только в контексте друг друга (не бывает предложений только со словом $x$ без $y$ в переводе и наоборот), равна 0, если слова никогда не встречаются в параллельных предложениях и находится между пороговыми значениями в остальных случаях.\n",
    "\n",
    "В файле `models.py` описан абстрактный класс `BaseAligner`, наследником которого должны являться все модели в задании, а также приведён пример реализации `DiceAligner` выравнивания слов описанным выше путём. Ниже вы можете увидеть, как применять эту модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DiceAligner\n",
    "\n",
    "baseline = DiceAligner(len(t_idx_src), len(t_idx_tgt), threshold=0.01)\n",
    "baseline.fit(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы оценить качество модели выравнивания, пользуясь имеющейся разметкой, существует ряд автоматических метрик. Они подразумевают, что в разметке есть два вида выравниваний — «уверенные» (sure) и «возможные» (possible). Обозначим для конкретного предложения первое множество выравниваний $S$, второе — $P$, а предсказанные выравнивания — $A$; причём, в отличие от разметки в файле, $S\\subseteq P$. Тогда можно предложить три метрики, используя только операции над этими множествами:\n",
    "\n",
    "Precision $=\\frac{|A\\cap P|}{|A|}$. Отражает, какая доля предсказанных нами выравниваний вообще корректна; если мы дадим в качестве ответа все возможные пары слов в предложении, эта метрика сильно просядет.\n",
    "\n",
    "Recall $=\\frac{|A\\cap S|}{|S|}$. Эта метрика показывает, какую долю «уверенных» выравниваний мы обнаружили. Если мы попытаемся сделать слишком консервативную модель, которая выдаёт 0 или 1 предсказание на нетривиальных предложениях, полнота получится крайне низкая. \n",
    "\n",
    "Alignment Error Rate (AER) $=1-\\frac{|A\\cap P|+|A\\cap S|}{|A|+|S|}$. Метрика является комбинацией двух предыдущих и отслеживает общее качество работы системы, штрафуя оба описанных выше вида нежелаемого поведения модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 0. (0.5 балла)** Реализуйте функции compute_precision, compute_recall, compute_aer из модуля metrics.py. Оцените качество бейзлайнового метода. Обратите внимание, что нужно использовать микро-усреднение во всех функциях: необходимо просуммировать числитель и знаменатель по всем предложениям и только потом делить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Замечание:**\n",
    "* **Для возможности получения полного балла** ошибка aer должна быть не выше **0.82.** Если получили значение выше -- скорее всего, у вас где-то ошибка\n",
    "* **Полностью проходящая все тесты посылка в этом заданиии дает 0.5 балла. За непроходящий хотя бы 1 тест вы получите 0 баллов.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**>>Ваша ссылка на посылку:<<**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import compute_aer\n",
    "\n",
    "compute_aer(all_targets,baseline.align(tokenized_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем перейти к базовой вероятностной модели для выравнивания слов. Пусть $S=(s_1,\\ldots,s_n)$ исходное предложение, $T=(t_1,\\ldots,t_m)$ — его перевод. В роли латентных переменных будут выступать выравнивания $A=(a_1,\\ldots,a_m)$ каждого слова в целевом предложении, причём $a_i\\in\\{1,\\ldots,n\\}$ (считаем, что каждое слово в $t$ является переводом какого-то слова из $s$). Параметрами модели является матрица условных вероятностей перевода: каждый её элемент $\\theta(y|x)=p(y|x)$ отражает вероятность того, что переводом слова $x$ с исходного языка на целевой является слово $y$ (нормировка, соответственно, совершается по словарю целевого языка). Правдоподобие латентных переменных и предложения на целевом языке в этой модели записывается так:\n",
    "\n",
    "$$\n",
    "p(A,T|S)=\\prod_{i=1}^m p(a_i)p(t_i|a_i,S)=\\prod_{i=1}^m \\frac{1}{n}\\theta(t_i|s_{a_i}).\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1. (2 балла)** Выведите шаги EM-алгоритма для этой модели, а также получите выражение для подсчёта нижней оценки правдоподобия ($\\mathcal{L}$ в обозначениях лекции и семинара). **Обратите внимание, что на M-шаге нужно найти аналитический максимум по параметрам.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Замечание:**\n",
    "* _Возможные форматы ответа:_ в ячейке ноутбука, отдельно сданная в энитаск pdf c набранными формулами в LaTex, отдельная сданная в энитаск фотография (или скан) рукописного (и разборчивого) вывода.\n",
    "* Наличие только ответа оценивается **в 0 баллов**\n",
    "* Наличие неочевидных переходов без пояснений влияет на **баллы в меньшую сторону**\n",
    "\n",
    "**Подсказка:**\n",
    "* Не забывайте об ограничениях по значению на $\\theta$, это должно быть тем или иным образом отображено в выводе шагов\n",
    "* Помните, что у вас в корпусе несколько предложений (положим их число равным $R$ например)\n",
    "* А также помните, что длины каждой пары (предложение, перевод) различны. Длины предложений $i-$й пары можно обозначать, например, как $n_i$ и $m_i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(∩｀-´)⊃━☆ﾟ.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2. (2 балла)** Реализуйте все методы класса `WordAligner` в соответствии с полученными вами формулами. Протестируйте вашу реализацию через Яндекс.Контест, а здесь обучите модель и посчитайте её AER на истинной разметке. Чтобы предсказать выравнивание для пары предложений в этой модели, следует выбирать в соответствие для слова в целевом предложении с индексом $i$ позицию, соответствующую максимуму апостериорного распределения $p(a_i|T,S)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Замечание:** \n",
    "* **Полностью проходящая все тесты посылка в этом заданиии дает 1 балл. За хотя бы 1 непройденный тест вы можете получить за это задание максимум 1 балл**\n",
    "* **Для возможности получения полного балла** ошибка aer должна быть не выше **0.6.** Если получили значение выше -- скорее всего, у вас где-то ошибка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**>>Ваша ссылка на посылку:<<**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import WordAligner\n",
    "\n",
    "word_aligner = WordAligner(len(t_idx_src), len(t_idx_tgt), 20)\n",
    "word_aligner.fit(tokenized_sentences);\n",
    "\n",
    "# ༼つ ಠ益ಠ༽つ ─=≡ΣO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что таблицу вероятностей перевода можно использовать и саму по себе для построения словарей. Пример работы показан ниже: метод хоть и работает, но мягко говоря, неидально — слишком мало данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_token_tgt = {index:token for token, index in t_idx_tgt.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['Mr']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['Mrs']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['water']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['depended']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['on']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3. (0.5 балла)** Мы смогли получить матрицу условных вероятностей перевода исходного языка в целевой. Можно ли, пользуясь этой матрицей и ещё какими-то статистиками по параллельному корпусу, получить вероятности перевода целевого языка в исходный?\n",
    "\n",
    "* **(?)**  Объясните словами принцип работы вашего метода и реализуйте его.\n",
    "* **(?)**  Также приведите ниже пример его работы, показав пару удачных переводов.\n",
    "\n",
    "**Подсказка:** какие формулы из теории вероятностей вы знаете? :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (>ω<)ノ—==ΞΞ☆*✲ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4. (0.5 балла)** Визуализируйте полученные выравнивания для нескольких предложений в виде heatmap: по одной из осей располагаются токены исходного текста, по другой — токены его перевода, на пересечении позиций $i$ и $j$ — 0 либо 1 в зависимости от того, является ли в обученной модели $a_i$ равным $j$. Проинтерпретируйте их.\n",
    "\n",
    "Постройте аналогичный график, но без дискретизации, а визуализируя напрямую апостериорное распределение. **(?)**  Можете ли вы найти ситуации, в которых модель не уверена, переводом какого слова является слово $i$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подсказка:**\n",
    "* Старайтесь не брать слишком короткие предложения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (•̀ 3 •́)━★☆.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонусная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что при задании модели мы сделали довольно сильное предположение о том, что вероятности выбора слова для выравнивания никак не зависят от позиции слова в целевом предложении. Можно сделать эти вероятности настраиваемыми параметрами, получив прямоугольную матрицу $\\phi_{m,n}(j|i)=p(a_i=j|m,n)$ для каждой пары длин предложений $m,n$: по-прежнему мы получаем распределение над индексами в исходном предложении. Тогда модель приобретает вид\n",
    "$$\n",
    "p(A,T|S)=\\prod_{i=1}^m p(a_i|m,n)p(t_i| a_i, S)=\\prod_{i=1}^m \\phi_{m,n}(a_i|i)\\theta(t_i|s_{a_i}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5. (бонус, 1.5 балла)** Выведите шаги EM-алгоритма для этой модели, а также получите выражение для подсчёта нижней оценки правдоподобия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Замечание:**\n",
    "* _Возможные форматы ответа:_ в ячейке ноутбука, отдельно сданная в энитаск pdf c набранными формулами в LaTex, отдельная сданная в энитаск фотография (или скан) рукописного (и разборчивого) вывода.\n",
    "* Наличие только ответа оценивается **в 0 баллов**\n",
    "* Наличие неочевидных переходов без пояснений влияет на **баллы в меньшую сторону**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ଘ(๑˃̵ᴗ˂̵)━☆ﾟ.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6. (бонус, 1.5 балла)** Реализуйте все методы класса `WordPositionAligner`, протестируйте их корректность через Яндекс.Контест. Обучите модель, оцените её качество на истинной разметке и сравните его с качеством предыдущей более простой модели. Проиллюстрируйте влияние стартовых параметров на результат, проинициализировав эту модель параметрами модели из задания 2 (важно, чтобы суммарное число эпох обучения в обоих сценариях оставалось тем же)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Замечание:** \n",
    "* **Полностью проходящая все тесты посылка в этом заданиии дает 0.75 балла. За хотя бы 1 непройденный тест вы можете получить за это задание максимум 0.75 балла**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**>>Ваша ссылка на посылку:<<**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import WordPositionAligner\n",
    "# (≧ ◡ ≦)━★☆.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 7. (бонус, 1 балл)** В предыдущих пунктах мы никак не заостряли внимание на предобработке текстов, что может негативно влиять на результаты обученной модели. Например, сейчас метод выравнивания учитывает регистр, а слова на чешском языке вдобавок обладают богатой морфологией и большим количеством диакритических знаков. Если сократить количество параметров модели (различных слов), можно ускорить обучение и добиться лучших результатов, потому что статистики по словам будут считаться по большему числу параллельных предложений.\n",
    "\n",
    "Примените к исходным данным [Unicode-нормализацию](https://en.wikipedia.org/wiki/Unicode_equivalence#Normalization), приведите их к нижнему регистру и обучите модель выравнивания заново. Сравните качество и скорость обучения с предыдущими результатами и сделайте выводы. Если вы найдете в данных ещё какие-то проблемы, которые можно исправить более грамотной предобработкой, также продемонстрируйте, как их решение влияет на качество.\n",
    "\n",
    "**Важно:** здесь и далее в процессе обработки данных у вас может получаться, что из тестовых данных будут удалены предложения из-за отсутствия слов в словаре. Если такое всё же произошло, для корректности сравнения считайте AER вашей модели на удалённых предложениях равным 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (੭•̀ω•́)੭̸*✩⁺˚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 8. (бонус, до 3 баллов)** \n",
    "\n",
    "Улучшите качество получившейся системы настолько, насколько сможете. За каждые 5 процентов, на которые AER на тех же данных получается меньше, чем минимум ошибки всех предыдущих моделей, вы получите по 1 бонусному баллу.\n",
    "\n",
    "Ниже приведены несколько идей, которые могут помочь вам повысить \n",
    "\n",
    "* Модифицировать модель: как вы можете понять, недостатком второго реализованного вами подхода является избыточное число параметров из-за необходимости подерживать отдельную матрицу для каждой различной пары длин предложений в корпусе. В статье https://www.aclweb.org/anthology/N13-1073.pdf приведён способ снижения числа параметров, задающих априорное распределение позиций выравнивания, который позволяет в десять раз быстрее обучать модель и получать лучшее качество.\n",
    "* Агрегация по двум направлениям: в статье https://www.aclweb.org/anthology/J03-1002/ утверждается, что асимметричность выравниваний вредит качеству, потому что из-за выбранной модели одному слову в целевом предложении не может соответствовать два слова в исходном предложении. Для решения этой проблемы (и улучшения метрик, разумеется) авторы предлагают несколько алгоритмов, которые можно попробовать применить в этом задании.\n",
    "* Использовать больше обучающих данных. В корпусе, которым мы пользуемся, только пара тысяч предложений, чего может не хватать для по-настоящему хорошей модели выравнивания. Разумеется, неразмеченных параллельных английско-чешских корпусов гораздо больше, поэтому можно воспользоваться ими. Хорошая точка для старта — данные с соревнования по машинному переводу  [воркшопа WMT](http://www.statmt.org/wmt20/translation-task.html).\n",
    "* В языках часто существуют слова наподобие артиклей или предлогов, которым не соответствует ни одно слово в переводе. Все рассмотренные в рамках задания модели это не учитывают, возможно, добавление возможности перевода в «нулевой» токен улучшит качество модели (при тестировании такие выравнивания имеет смысл выбрасывать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ┐_(ツ)_┌━☆ﾟ.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Картинка для поддержки ваших чувств по этому заданию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://a.d-cd.net/RAAAAgCnO-A-960.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
